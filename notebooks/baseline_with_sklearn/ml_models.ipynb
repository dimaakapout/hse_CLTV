{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Простое прогнозирование CLTV\n",
    "\n",
    "    I. Дизайн эксперимента. Pipeline\n",
    "        1 Вход\n",
    "        2 Preprocessing\n",
    "        3 Обучение моделей\n",
    "        4 Оценка качества\n",
    "    II. Реализация\n",
    "        II.I Preprocessing\n",
    "        II.II Обучение моделей\n",
    "        II.III Оценка качества\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# I. Дизайн эксперимента. Pipeline\n",
    "\n",
    "### 1 Вход - журнал транзакций с 1.01.1997 по 30.06.1998\n",
    "  * `cust` - client ID\n",
    "  * `date` - date\n",
    "  * `sales` - сумма операции (сделки, покупки)\n",
    "![](01_transaction_head.JPG)\n",
    "\n",
    "### 2 Preprocessing\n",
    "\n",
    "### 2.1 Разбиваем выборку на 3 части (обучение, тест, валидация)\n",
    "Весь датасет будет разбит на три части:\n",
    "    1. Обучающий набор (24 недели на обучение, 8 следующих недель на оценку)\n",
    "    2. Калибровочный (тестовый) набор (предсказание по данным за 24 нелели, 8 следующих недель на оценку)\n",
    "    3. Валидационный набор (предсказание по данным за 24 нелели, 8 следующих недель на оценку)\n",
    "![](02_traintestsplit.jpg)\n",
    "\n",
    "### 2.2 Вычисление признакового описания для каждого набора\n",
    "В качестве признаков пока используется набор признаков, аналогичный Pareto/NBD модели.\n",
    "\n",
    "Т.е. это матрица `\"object - feature\"`. Строки матрицы соотв `client ID`. А Стобцы - признакам клиентов, составленным на основе истории их поведения (взаимодействия):\n",
    "* `Recency` - время между первой и последней покупкой\n",
    "* `Frequency` - частота дейтвией (кол-во покупок - 1)\n",
    "* `monetary value` - среднее кол-во по плажам на дату \n",
    "* `T` - время между последней покупкой и текущей датой\n",
    "![](03_features_rfm.JPG)\n",
    "\n",
    "### 3 Обучение моделей\n",
    "Использовались следующие:\n",
    "    1. Linear Regression\n",
    "    2. RandomForest\n",
    "    3. SVMRegressor\n",
    "    4. Boosting (sklearn.ensemble.GradientBoostingRegressor)\n",
    "    5. Стекинг RF и бустинга\n",
    "### 4 Оценка качества\n",
    "\n",
    "В качестве основной метрики выбрана `RMSLE`, но в справочных целях приведены также `RMSE`, `MAE`, `MAPE`, `R-квадрат`.\n",
    "\n",
    "#### 4.1 RMSLE\n",
    "![](04_rmsle.JPG)\n",
    "##### 4.1.1 Достоинства \n",
    "* Устойчива к выбросам (за счет применения log-функции)\n",
    "* Вычисляет **относительную** ошибку между прогнозируемым и фактическим значением, масштаб ошибки не имеет значения.\n",
    "* **RMSLE сильнее штрафует за недооценку фактической переменной, чем за ее завышение.**\n",
    "##### 4.1.2 Недостатки\n",
    "* Не для всех задач подходит (*x* должен быть более 1)\n",
    "\n",
    "\n",
    "#### 4.2 RMSE\n",
    "![](04_rmse.JPG)\n",
    "\n",
    "##### 4.2.1 Достоинства\n",
    "* За счет возведения ошибки в степень сильнее штрафует за большие отклонения\n",
    "* Удобно трактовать, т.к. в тех же ед.измерения что и целевая переменная\n",
    "* Дифференцируемая функция (MSE) подходит для применения методов оптимизации\n",
    "##### 4.2.1 Недостатки\n",
    "* бесполезна для сравнения двух и более моделей, предсказывающих одно и тоже по разным признакам\n",
    "\n",
    "#### 4.3 MAE\n",
    "![](04_mae.JPG)\n",
    "\n",
    "##### 4.3.1 Достоинства\n",
    "* Удобно трактовать, т.к. в тех же ед.измерения что и целевая переменная\n",
    "\n",
    "##### 4.3.2 Недостатки\n",
    "* Одинаково штрафует за расхождение (напр.в 2 и 200 ед.)\n",
    "* бесполезна для сравнения двух и более моделей, предсказывающих одно и тоже по разным признакам\n",
    "* Недифференцируемая функция \n",
    "\n",
    "#### 4.4 MAPE [upd. НЕ ИСПОЛЬЗУЕМ]\n",
    "![](04_mape.JPG)\n",
    "\n",
    "##### 4.4.1 Достоинства\n",
    "* Удобно интерпретировать. Позволяет абстрагироваться от конкретных цифр и быстро понять, на сколько % разошлись прогноз и результат\n",
    "* Может вылавливать ошибки разного веса там, где MSE и MAE показали бы одинаковое расхождение для двух разных случаев\n",
    "\n",
    "##### 4.4.2 Недостатки\n",
    "* Не подходит для задач, где нужно работать с реальными единицами измерения (деньги, время, штуки и пр)\n",
    "* Может возникать деление на 0 (если y true = 0)\n",
    "\n",
    "#### 4.5 R-квадрат (R^2)\n",
    "![](04_r2.JPG)\n",
    "\n",
    "##### 4.5.1 Достоинства\n",
    "* Помогает понять какую долю разнообразия данных модель смогла объяснить\n",
    "* можно сравнивать модели, обученные на разных данных\n",
    "* Легко оценить качество (>0.5 it's OK)\n",
    "\n",
    "##### 4.5.2 Недостатки\n",
    "* Чувствительная к добавлению новых данных\n",
    "\n",
    "### * Общая схема \n",
    "![](05_bigimg.JPG)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# II.I Реализация. Препроцессинг"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np \n",
    "import matplotlib.pyplot as plt\n",
    "import datetime as dt \n",
    "%matplotlib inline \n",
    "%pylab inline\n",
    "pylab.rcParams['figure.figsize'] = (10, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load data\n",
    "transactions = pd.read_csv(r'transaction_log.csv')\n",
    "transactions['date'] = pd.to_datetime(transactions['date'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create timelines\n",
    "\n",
    "fitPeriod = 7*4*6 # Длина временного промежутка, на котором учимся\n",
    "evaluatePeriod = 7*4*2 # Длина промежутка, на котором оцениваемся\n",
    "\n",
    "# train\n",
    "trainStartDate = pd.Timestamp(dt.date(1997, 1, 1))\n",
    "trainEndDate = trainStartDate + dt.timedelta(fitPeriod)\n",
    "traineEvaluateDate = trainEndDate + dt.timedelta(evaluatePeriod)\n",
    "\n",
    "# test\n",
    "testStartDate = trainEndDate + dt.timedelta(1)\n",
    "testEndDate = testStartDate  + dt.timedelta(fitPeriod)\n",
    "testEvaluateDate = testEndDate + dt.timedelta(evaluatePeriod)\n",
    "\n",
    "# validation\n",
    "valStartDate = testEndDate + dt.timedelta(1)\n",
    "valEndDate = valStartDate + dt.timedelta(fitPeriod)\n",
    "valEvaluateDate = valEndDate + dt.timedelta(evaluatePeriod)\n",
    "\n",
    "# fixCustDate = dt.date(1997, 3, 25) \n",
    "# endDate =  dt.date(1998, 6, 30) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #fig1\n",
    "# fig, ax = plt.subplots(2,1, figsize=(15,10), sharex = True)\n",
    "# ax[0].fill_between(x = [trainStartDate,trainEndDate], \n",
    "#                 y1 = 3, y2=4, color='green', label='train')\n",
    "# ax[0].fill_between(x = [trainEndDate,traineEvaluateDate], \n",
    "#                 y1 = 3, y2=4, color='blue')\n",
    "# ax[0].fill_between(x = [testStartDate,testEndDate], \n",
    "#                 y1 = 2, y2=3, color='orange', label='test')\n",
    "# ax[0].fill_between(x = [testEndDate,testEvaluateDate], \n",
    "#                 y1 = 2, y2=3, color='blue')\n",
    "# ax[0].fill_between(x = [valStartDate,valEndDate], \n",
    "#                 y1 = 1, y2=2, color='red', label='validation')\n",
    "# ax[0].fill_between(x = [valEndDate,valEvaluateDate], \n",
    "#                 y1 = 1, y2=2, color='blue', label='evaluate')\n",
    "\n",
    "# for l in [trainStartDate, trainEndDate, traineEvaluateDate, \n",
    "#          testStartDate, testEndDate, testEvaluateDate,\n",
    "#          valStartDate, valEndDate, valEvaluateDate]:\n",
    "#     ax[0].axvline(l, c='k', linestyle=':')\n",
    "# ax[0].set_yticklabels([])\n",
    "# ax[0].set_title('Данные для подготовки модели поделим таким образом, 6мес на обучение, 2мес на оценку')\n",
    "# _ = ax[0].legend(loc=1)\n",
    "\n",
    "# #fig2\n",
    "# _ = transactions.cust.max()\n",
    "# #fig, ax = plt.subplots(1,1, figsize=(15,5), sharex = True)\n",
    "# ax[1].scatter(x=transactions.date.values, y=transactions.cust,  edgecolor='k')\n",
    "# ax[1].fill_between(x = [trainStartDate,trainEndDate], \n",
    "#                 y1 = 0, y2=_, color='green', label='train', alpha=0.2)\n",
    "# ax[1].fill_between(x = [testStartDate,testEndDate], \n",
    "#                 y1 = 2, y2=_, color='orange', label='test', alpha=0.2)\n",
    "# ax[1].fill_between(x = [valStartDate,valEndDate], \n",
    "#                 y1 = 1, y2=_, color='red', label='validation', alpha=0.2)\n",
    "# ax[1].set_title('Другое представление разбиения данных')\n",
    "# ax[1].set_ylabel('Фиксация активности клиента \\nна временном горизонте\\n согласно его ID')\n",
    "# _ = plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3929, 3)\n",
      "(502, 3)\n",
      "(1393, 3)\n",
      "(401, 3)\n",
      "(1140, 3)\n",
      "(222, 3)\n"
     ]
    }
   ],
   "source": [
    "# create train, test, val datasets\n",
    "# train\n",
    "train = transactions[transactions.date < trainEndDate]\n",
    "trainEval = transactions[(transactions.date >= trainEndDate)&(transactions.date <= traineEvaluateDate)]\n",
    "# test\n",
    "test = transactions[(transactions.date >= testStartDate)&(transactions.date < testEndDate)]\n",
    "testEval = transactions[(transactions.date >= testEndDate)&(transactions.date <= testEvaluateDate)]\n",
    "# val\n",
    "val = transactions[(transactions.date >= valStartDate)&(transactions.date < valEndDate)]\n",
    "valEval = transactions[(transactions.date >= valEndDate)&(transactions.date <= valEvaluateDate)]\n",
    "\n",
    "for i in [train, trainEval, test, testEval, val, valEval]: print(i.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Вычисление целевой перменной - сумма дохода за период по каждому клиенту\n",
    "\n",
    "def make_y_true(train, test):\n",
    "    '''\n",
    "    Parameters:\n",
    "    -------\n",
    "        train, test: pandas.DataFrame with columns: cust,sales\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    pandas.Series\n",
    "    \n",
    "    '''\n",
    "    test = test.groupby('cust').sales.sum().rename('test')\n",
    "    var1 = train.groupby('cust').sum().rename(columns={'sales':'train'})\n",
    "    # Учитываем в test только тех клиентов, которые есть в train\n",
    "    var2 = var1.merge(pd.DataFrame(test), left_on='cust', right_on='cust', how='left') \n",
    "    var2.test = var2.test.apply(lambda x: x if x>0 else 0)\n",
    "    y_true = var2.test\n",
    "   \n",
    "    return y_true\n",
    "\n",
    "# CLTV really\n",
    "yTrue_train = make_y_true(train, trainEval)\n",
    "yTrue_test = make_y_true(test, testEval)\n",
    "yTrue_val = make_y_true(val, valEval)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Блок для вычисления признаков клиентов по transaction log\n",
    "\n",
    "def shift_date(x): \n",
    "    # посмотрим на смещение во времени, через сколько была следующая покупка\n",
    "    x['shifted_date'] = x['date'].shift(-1) \n",
    "    return x\n",
    "\n",
    "\n",
    "\n",
    "def compute_rfm(x, end_calibration):\n",
    "    # функция на весь RFM\n",
    "    x['recency'] = (x['date'].max() - x['date'].min()).days\n",
    "    x['frequency'] = x['date'].count()-1\n",
    "    x['T'] = (end_calibration - x['date'].min()).days\n",
    "    x['monetary_value'] = x['sales'].mean()\n",
    "    return x\n",
    "\n",
    "def make_x(transactions, end_calibration):\n",
    "\n",
    "    # Вычисляем М параметр на покупателя и дату\n",
    "\n",
    "    train2 = transactions.sort_values(['date'], ascending=True)\\\n",
    "              .groupby(['cust', 'date'], \n",
    "                        as_index=False)['sales'].sum()    \n",
    "    # RFM\n",
    "    train3 = train2.groupby(['cust']).apply(lambda x: compute_rfm(x, end_calibration))\n",
    "    # отбираем 1 строку, которая показывает агрегированные данные пользователя\n",
    "    rfm = train3[['cust', 'recency', 'frequency', 'T', 'monetary_value']].groupby(['cust']).first()\n",
    "    \n",
    "    return rfm\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "Xtrain = make_x(train, trainEndDate)\n",
    "Xtest = make_x(test, testEndDate)\n",
    "Xval = make_x(val, valEndDate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2357, 4) (2357,)\n",
      "(629, 4) (629,)\n",
      "(526, 4) (526,)\n"
     ]
    }
   ],
   "source": [
    "for i,j in ((Xtrain, yTrue_train), (Xtest, yTrue_test), (Xval, yTrue_val)):\n",
    "            print(i.shape, j.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# II.II Обучение моделей\n",
    "\n",
    "Пока без особого подбора гиперпараметров"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn\n",
    "from sklearn.linear_model import LinearRegression, SGDRegressor, Lasso\n",
    "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor\n",
    "from sklearn.metrics import mean_absolute_error, r2_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### II.II.I Linear regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LinearRegression(copy_X=True, fit_intercept=True, n_jobs=1, normalize=False)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "modelLinReg = LinearRegression()\n",
    "modelLinReg.fit(Xtrain, yTrue_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### II.II.II Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestRegressor(bootstrap=True, criterion='mse', max_depth=10,\n",
       "           max_features='auto', max_leaf_nodes=None,\n",
       "           min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "           min_samples_leaf=1, min_samples_split=2,\n",
       "           min_weight_fraction_leaf=0.0, n_estimators=100, n_jobs=1,\n",
       "           oob_score=False, random_state=None, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "modelRF = RandomForestRegressor(max_depth=10, n_estimators=100)\n",
    "modelRF.fit(Xtrain, yTrue_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GradientBoostingRegressor(alpha=0.9, criterion='friedman_mse', init=None,\n",
       "             learning_rate=0.1, loss='ls', max_depth=3, max_features=None,\n",
       "             max_leaf_nodes=None, min_impurity_decrease=0.0,\n",
       "             min_impurity_split=None, min_samples_leaf=1,\n",
       "             min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
       "             n_estimators=100, presort='auto', random_state=None,\n",
       "             subsample=1.0, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "modelGrBoost = GradientBoostingRegressor()\n",
    "modelGrBoost.fit(Xtrain, yTrue_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# stacking\n",
    "class custommodel:\n",
    "    def __init__(self, *args):\n",
    "        self.models = args\n",
    "    def predict(self, x):\n",
    "        return np.array([m.predict(x) for m in self.models[0]]).mean(axis=0) # смешаем в пропорции 50/50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "_ = custommodel([modelRF, modelGrBoost])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Мешок моделей\n",
    "bagWithModels = {'model_name':('LinReg', 'RF', 'GrBoost', 'RF+GrBoost'),  \n",
    "                'models': (modelLinReg, modelRF, modelGrBoost, _)}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# II.III Оценка качества"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Некоторые модели предсказывают отрицательные LTV\n",
    "# Поэтому в таких предсказаниях нужно заменять отрицательные значения на ноль\n",
    "\n",
    "def func(x):\n",
    "    return x if x>=0 else 0\n",
    "vfunc = np.vectorize(func)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# RMSLE function\n",
    "\n",
    "def rmsle(ytrue, ypred):\n",
    "    '''\n",
    "    Parameters:\n",
    "    -------\n",
    "        ytrue, ypred: pandas.Series or  numpy.array\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    float\n",
    "    '''\n",
    "    return np.sqrt(((np.log(ypred + 1) - np.log(ytrue + 1))**2).mean())\n",
    "\n",
    "def fastEval(model, x, y):\n",
    "    '''Обучения и метрика быстро, для отладки'''\n",
    "    model.fit(x,y)\n",
    "    y_pr = vfunc(model.predict(x))\n",
    "    return rmsle(y, y_pr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics = (rmsle, mean_absolute_error, r2_score)\n",
    "metric_names = ('RMSLE', 'MAE', 'R2')\n",
    "yTrues = (yTrue_train, yTrue_test, yTrue_val)\n",
    "_names = ('_train', '_test', '_val')\n",
    "X = (Xtrain, Xtest, Xval)\n",
    "\n",
    "shape = (len(bagWithModels['model_name']), len(metric_names)*len(_names)) #(rows, cols)\n",
    "summary = pd.DataFrame(np.zeros(shape).reshape(shape), \n",
    "             columns=[mn+n for mn in metric_names for n in _names],\n",
    "             index=bagWithModels['model_name'])\n",
    "\n",
    "# Для каждой модели вычисляем метрики на train, test, val\n",
    "for model, model_name in zip(bagWithModels['models'], bagWithModels['model_name']):\n",
    "    for metric, metric_name in zip(metrics, metric_names):\n",
    "        for yTrue, x, _name in zip(yTrues, X, _names):\n",
    "            yPred = vfunc(model.predict(x)) # Делаем предсказание !vfunc!\n",
    "            summary.loc[model_name][metric_name+_name] = metric(yTrue, yPred) # Вычисляем метрику"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>RMSLE_train</th>\n",
       "      <th>RMSLE_test</th>\n",
       "      <th>RMSLE_val</th>\n",
       "      <th>MAE_train</th>\n",
       "      <th>MAE_test</th>\n",
       "      <th>MAE_val</th>\n",
       "      <th>R2_train</th>\n",
       "      <th>R2_test</th>\n",
       "      <th>R2_val</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>LinReg</th>\n",
       "      <td>1.821883</td>\n",
       "      <td>2.001969</td>\n",
       "      <td>2.134460</td>\n",
       "      <td>11.944272</td>\n",
       "      <td>18.884941</td>\n",
       "      <td>16.163253</td>\n",
       "      <td>0.118884</td>\n",
       "      <td>0.253117</td>\n",
       "      <td>0.069806</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RF</th>\n",
       "      <td>1.390818</td>\n",
       "      <td>2.078574</td>\n",
       "      <td>2.176363</td>\n",
       "      <td>6.885826</td>\n",
       "      <td>21.297887</td>\n",
       "      <td>19.106258</td>\n",
       "      <td>0.789711</td>\n",
       "      <td>0.097237</td>\n",
       "      <td>-0.474691</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GrBoost</th>\n",
       "      <td>1.650046</td>\n",
       "      <td>1.944061</td>\n",
       "      <td>2.068738</td>\n",
       "      <td>9.296560</td>\n",
       "      <td>19.981979</td>\n",
       "      <td>17.818486</td>\n",
       "      <td>0.603103</td>\n",
       "      <td>0.071833</td>\n",
       "      <td>-0.418311</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RF+GrBoost</th>\n",
       "      <td>1.524883</td>\n",
       "      <td>2.016776</td>\n",
       "      <td>2.135052</td>\n",
       "      <td>8.041016</td>\n",
       "      <td>20.502340</td>\n",
       "      <td>18.346815</td>\n",
       "      <td>0.714798</td>\n",
       "      <td>0.112689</td>\n",
       "      <td>-0.384626</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            RMSLE_train  RMSLE_test  RMSLE_val  MAE_train   MAE_test  \\\n",
       "LinReg         1.821883    2.001969   2.134460  11.944272  18.884941   \n",
       "RF             1.390818    2.078574   2.176363   6.885826  21.297887   \n",
       "GrBoost        1.650046    1.944061   2.068738   9.296560  19.981979   \n",
       "RF+GrBoost     1.524883    2.016776   2.135052   8.041016  20.502340   \n",
       "\n",
       "              MAE_val  R2_train   R2_test    R2_val  \n",
       "LinReg      16.163253  0.118884  0.253117  0.069806  \n",
       "RF          19.106258  0.789711  0.097237 -0.474691  \n",
       "GrBoost     17.818486  0.603103  0.071833 -0.418311  \n",
       "RF+GrBoost  18.346815  0.714798  0.112689 -0.384626  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summary"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
